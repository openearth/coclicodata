{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58b6628a",
   "metadata": {},
   "source": [
    "# Storm surge level\n",
    "\n",
    "Notebook environment to migrate netcdf files to CF compliant zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d213fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional; code formatter, installed as jupyter lab extension\n",
    "#%load_ext lab_black\n",
    "# Optional; code formatter, installed as jupyter notebook extension\n",
    "%load_ext nb_black"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "892785ae",
   "metadata": {},
   "source": [
    "### Configure OS independent paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "# Make root directories importable by appending root to path\n",
    "cwd = pathlib.Path().resolve()\n",
    "sys.path.append(os.path.dirname(cwd))\n",
    "\n",
    "# Get root paths\n",
    "home = pathlib.Path().home()\n",
    "root = home.root\n",
    "\n",
    "# Import custom functionality\n",
    "from etl import p_drive\n",
    "from etl.CF_compliancy_checker import check_compliancy, save_compliancy\n",
    "\n",
    "# Define (local and) remote drives\n",
    "coclico_data_dir = p_drive.joinpath(\"11205479-coclico\", \"FASTTRACK_DATA\")\n",
    "\n",
    "# Workaround to the Windows OS (10) udunits error after installation of cfchecker: https://github.com/SciTools/iris/issues/404\n",
    "os.environ[\"UDUNITS2_XML_PATH\"] = str(\n",
    "    home.joinpath(  # change to the udunits2.xml file dir in your Python installation\n",
    "        r\"Anaconda3\\pkgs\\udunits2-2.2.28-h892ecd3_0\\Library\\share\\udunits\\udunits2.xml\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c526d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project paths & files (manual input)\n",
    "dataset_dir = coclico_data_dir.joinpath(\"01_storm_surge_jrc\")\n",
    "dataset_historical_path = dataset_dir.joinpath(\"CoastAlRisk_Europe_EESSL_Historical.nc\")\n",
    "dataset_rcp45_path = dataset_dir.joinpath(\"CoastAlRisk_Europe_EESSL_RCP45.nc\")\n",
    "dataset_rcp85_path = dataset_dir.joinpath(\"CoastAlRisk_Europe_EESSL_RCP85.nc\")\n",
    "dataset_out_file = \"CoastAlRisk_Europe_EESSL\"\n",
    "CF_dir = coclico_data_dir.joinpath(r\"CF\")  # directory to save output CF check files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8d5c913",
   "metadata": {},
   "source": [
    "### Check CF compliancy original NetCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open datasets\n",
    "dataset_historical = xr.open_dataset(dataset_historical_path)\n",
    "dataset_45rcp = xr.open_dataset(dataset_rcp45_path)\n",
    "dataset_85rcp = xr.open_dataset(dataset_rcp85_path)\n",
    "\n",
    "# check original dataset\n",
    "dataset_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# check original CF compliancy\n",
    "\n",
    "check_compliancy(testfile=dataset_historical_path, working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5550244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save original CF compliancy\n",
    "save_compliancy(cap, testfile=dataset_historical_path, working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6632d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# check original CF compliancy\n",
    "\n",
    "check_compliancy(testfile=dataset_rcp45_path, working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f94a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save original CF compliancy\n",
    "save_compliancy(cap, testfile=dataset_rcp45_path, working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e69f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# check original CF compliancy\n",
    "\n",
    "check_compliancy(testfile=dataset_rcp85_path, working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save original CF compliancy\n",
    "save_compliancy(cap, testfile=dataset_rcp85_path, working_dir=CF_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ba9aa6e",
   "metadata": {},
   "source": [
    "### Make CF compliant alterations to the NetCDF files (dataset dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4aae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetCDF attribute alterations\n",
    "\n",
    "# rename global attribute names\n",
    "dataset_historical.attrs[\"Project_Name\"] = dataset_historical.attrs.pop(\"Project Name\")\n",
    "dataset_historical.attrs[\"Project_Acronym\"] = dataset_historical.attrs.pop(\n",
    "    \"Project Acronym\"\n",
    ")\n",
    "dataset_45rcp.attrs[\"Project_Name\"] = dataset_45rcp.attrs.pop(\"Project Name\")\n",
    "dataset_45rcp.attrs[\"Project_Acronym\"] = dataset_45rcp.attrs.pop(\"Project Acronym\")\n",
    "dataset_85rcp.attrs[\"Project_Name\"] = dataset_85rcp.attrs.pop(\"Project Name\")\n",
    "dataset_85rcp.attrs[\"Project_Acronym\"] = dataset_85rcp.attrs.pop(\"Project Acronym\")\n",
    "\n",
    "# add global attributes\n",
    "dataset_historical.attrs[\"Conventions\"] = \"CF-1.8\"\n",
    "dataset_45rcp.attrs[\"Conventions\"] = \"CF-1.8\"\n",
    "dataset_85rcp.attrs[\"Conventions\"] = \"CF-1.8\"\n",
    "dataset_historical.attrs[\"Starting_date\"] = \"01-Dec-1969\"\n",
    "dataset_historical.attrs[\"End_date\"] = \"30-Nov-2004 21:00:00\"\n",
    "dataset_45rcp.attrs[\"Starting_date\"] = \"01-Dec-2009\"\n",
    "dataset_45rcp.attrs[\"End_date\"] = \"30-Nov-2099 21:00:00\"\n",
    "dataset_85rcp.attrs[\"Starting_date\"] = \"01-Dec-2009\"\n",
    "dataset_85rcp.attrs[\"End_date\"] = \"30-Nov-2099 21:00:00\"\n",
    "\n",
    "# remove certain variable attributes\n",
    "del dataset_historical[\"RP\"].attrs[\"Starting date\"]\n",
    "del dataset_historical[\"RP\"].attrs[\"End date\"]\n",
    "del dataset_45rcp[\"RP\"].attrs[\"Starting date\"]\n",
    "del dataset_45rcp[\"RP\"].attrs[\"End date\"]\n",
    "del dataset_85rcp[\"RP\"].attrs[\"Starting date\"]\n",
    "del dataset_85rcp[\"RP\"].attrs[\"End date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf79ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetCDF variable and dimension alterations\n",
    "\n",
    "# rename or swap dimension names, the latter in case the name already exists as coordinate\n",
    "dataset_historical = dataset_historical.rename_dims({\"row\": \"stations\"})\n",
    "dataset_45rcp = dataset_45rcp.rename_dims({\"row\": \"stations\"})\n",
    "dataset_85rcp = dataset_85rcp.rename_dims({\"row\": \"stations\"})\n",
    "dataset_historical = dataset_historical.swap_dims({\"col\": \"rp\"})\n",
    "dataset_45rcp = dataset_45rcp.swap_dims({\"col\": \"rp\"})\n",
    "dataset_85rcp = dataset_85rcp.swap_dims({\"col\": \"rp\"})\n",
    "\n",
    "# rename variables, if necessary\n",
    "dataset_historical = dataset_historical.rename_vars(\n",
    "    {\"RP\": \"rp\", \"longitude\": \"lon\", \"latitude\": \"lat\"}\n",
    ")\n",
    "dataset_45rcp = dataset_45rcp.rename_vars(\n",
    "    {\"RP\": \"rp\", \"longitude\": \"lon\", \"latitude\": \"lat\"}\n",
    ")\n",
    "dataset_85rcp = dataset_85rcp.rename_vars(\n",
    "    {\"RP\": \"rp\", \"longitude\": \"lon\", \"latitude\": \"lat\"}\n",
    ")\n",
    "\n",
    "# set some data variables to coordinates to avoid duplication of dimensions in later stage\n",
    "dataset_historical = dataset_historical.set_coords([\"lon\", \"lat\", \"rp\"])\n",
    "dataset_45rcp = dataset_45rcp.set_coords([\"lon\", \"lat\", \"rp\"])\n",
    "dataset_85rcp = dataset_85rcp.set_coords([\"lon\", \"lat\", \"rp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat datasets along new dimension with index values and name derived from pandas index object, if necessary\n",
    "dataset = xr.concat(\n",
    "    [dataset_historical, dataset_45rcp, dataset_85rcp], dim=\"nscenarios\",\n",
    ")\n",
    "dataset = dataset.assign_coords(\n",
    "    scenarios=(\"nscenarios\", np.array([\"Historical\", \"RCP45\", \"RCP85\"], dtype=\"S\"))\n",
    ")\n",
    "\n",
    "# dataset = xr.concat(\n",
    "#     [dataset_historical, dataset_45rcp, dataset_85rcp],\n",
    "#     pd.Index([\"historical\", \"rcp45\", \"rcp85\"], name=\"scenarios\"),\n",
    "# )\n",
    "\n",
    "# dataset[\"scenarios\"].values.astype(\"U\") # retrieve scenarios as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-order shape of the data variables\n",
    "dataset_historical = dataset_historical.transpose(\"stations\", \"rp\")\n",
    "dataset_45rcp = dataset_45rcp.transpose(\"stations\", \"rp\")\n",
    "dataset_85rcp = dataset_85rcp.transpose(\"stations\", \"rp\")\n",
    "dataset = dataset.transpose(\"nscenarios\", \"stations\", \"rp\")\n",
    "\n",
    "# add or change certain variable / coordinate attributes\n",
    "dataset_attributes = {\n",
    "    \"scenarios\": {\"long_name\": \"climate scenarios\"}\n",
    "}  # specify custom (CF convention) attributes\n",
    "\n",
    "# add / overwrite attributes\n",
    "for k, v in dataset_attributes.items():\n",
    "    try:\n",
    "        dataset[k].attrs = dataset_attributes[k]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# add epsg\n",
    "dataset_historical.attrs[\"crs\"] = 4326\n",
    "dataset_45rcp.attrs[\"crs\"] = 4326\n",
    "dataset_85rcp.attrs[\"crs\"] = 4326\n",
    "dataset.attrs[\"crs\"] = 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the xarray dataset, best practice is to have as many as possible bold dimensions (dimension == coordinate name).\n",
    "# in this way, the Front-End can access the variable directly without having to index the variable first\n",
    "\n",
    "dataset\n",
    "# dataset[\"scenarios\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f59c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new .nc files\n",
    "dataset_historical.to_netcdf(path=str(dataset_historical_path).replace(\".nc\", \"_CF.nc\"))\n",
    "dataset_45rcp.to_netcdf(path=str(dataset_rcp45_path).replace(\".nc\", \"_CF.nc\"))\n",
    "dataset_85rcp.to_netcdf(path=str(dataset_rcp85_path).replace(\".nc\", \"_CF.nc\"))\n",
    "dataset.to_netcdf(path=dataset_dir.joinpath(dataset_out_file + \"_CF.nc\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb6b7ed5",
   "metadata": {},
   "source": [
    "### Check CF compliancy altered NetCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2128ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# check altered CF compliancy\n",
    "\n",
    "check_compliancy(testfile=str(dataset_historical_path).replace(\".nc\", \"_CF.nc\"), working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save altered CF compliancy\n",
    "save_compliancy(\n",
    "    cap,\n",
    "    testfile=str(dataset_historical_path).replace(\".nc\", \"_CF.nc\"),\n",
    "    working_dir=CF_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# check altered CF compliancy\n",
    "\n",
    "check_compliancy(testfile=str(dataset_rcp45_path).replace(\".nc\", \"_CF.nc\"), working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185059c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save altered CF compliancy\n",
    "save_compliancy(\n",
    "    cap, testfile=str(dataset_rcp45_path).replace(\".nc\", \"_CF.nc\"), working_dir=CF_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# check altered CF compliancy\n",
    "\n",
    "check_compliancy(testfile=str(dataset_rcp85_path).replace(\".nc\", \"_CF.nc\"), working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916365dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save altered CF compliancy\n",
    "save_compliancy(\n",
    "    cap, testfile=str(dataset_rcp85_path).replace(\".nc\", \"_CF.nc\"), working_dir=CF_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# check altered CF compliancy\n",
    "\n",
    "check_compliancy(testfile=dataset_dir.joinpath(dataset_out_file + \"_CF.nc\"), working_dir=CF_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save altered CF compliancy\n",
    "save_compliancy(\n",
    "    cap, testfile=dataset_dir.joinpath(dataset_out_file + \"_CF.nc\"), working_dir=CF_dir,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8155e887",
   "metadata": {},
   "source": [
    "### write data to Zarr files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d91d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to zarr in write mode (to overwrite if exists)\n",
    "dataset.to_zarr(dataset_dir.joinpath(\"%s.zarr\" % dataset_out_file), mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88359b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "92590b8b61d447ec77a1c897af89012828c879bd382a813b35f1d19994b1169c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
