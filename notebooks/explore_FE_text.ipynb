{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pystac\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded STAC templates\n",
    "CUR_CWD = Path.cwd().parent\n",
    "STAC_DIR = CUR_CWD / \"current\"  # .parent.parent\n",
    "\n",
    "# Load catalog using pystac_client\n",
    "catalog = pystac.Catalog.from_file(str(STAC_DIR / \"catalog.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Sea level rise projections** provide regional insights into future sea level changes, helping assess coastal flood risks and inform adaptation planning.  \\n\\n- **Spatial coverage:** Global Ocean and European seas  \\n- **Sources:** IPCC AR6 report, Caron et al. Glacial Isostatic Adjustment (GIA), CMIP6  \\n- **Common usage:** Coastal impact assessment, adaptation planning, sensitivity analysis  \\n\\nMore info about the dataset can be found in the <a href='https://www.openearth.nl/coclico-workbench/Datasets/#__tabbed_1_1' target='_blank' rel='noopener noreferrer'>User Handbook</a>\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_text_file = Path(r\"p:\\11207608-coclico\\docs\\FE_text_titles.xlsx\")\n",
    "fe_text = pd.read_excel(fe_text_file, sheet_name=\"Sheet1\")\n",
    "fe_text\n",
    "\n",
    "# Get single cell information\n",
    "slp_description = fe_text.loc[fe_text[\"Collection\"] == \"slp\", \"Markdown\"].values[0]\n",
    "\n",
    "slp_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set labels for FE\n",
    "fe_labels = {\n",
    "    \"defense level\": {\n",
    "        \"HIGH_DEFENDED_MAPS\": \"High Defended\",\n",
    "        \"LOW_DEFENDED_MAPS\": \"Low Defended\",\n",
    "        \"UNDEFENDED_MAPS\": \"No Defense\"\n",
    "    },\n",
    "    \"return period\": {\n",
    "        \"static\": \"No Return Period\",\n",
    "        \"1\": \"1 year\",\n",
    "        \"5\": \"5 years\",\n",
    "        \"10\": \"10 years\",\n",
    "        \"20\": \"20 years\",\n",
    "        \"50\": \"50 years\",\n",
    "        \"100\": \"100 years\",\n",
    "        \"200\": \"200 years\",\n",
    "        \"500\": \"500 years\",\n",
    "        \"1000\": \"1000 years\"\n",
    "    },\n",
    "    \"rp\": {\n",
    "        \"static\": \"No Return Period\",\n",
    "        \"1\": \"1 year\",\n",
    "        1.0: \"1 year\",\n",
    "        \"5\": \"5 years\",\n",
    "        5.0: \"5 years\",\n",
    "        \"10\": \"10 years\",\n",
    "        10.0: \"10 years\",\n",
    "        \"20\": \"20 years\",\n",
    "        20.0: \"20 years\",\n",
    "        \"50\": \"50 years\",\n",
    "        50.0: \"50 years\",\n",
    "        \"100\": \"100 years\",\n",
    "        100.0: \"100 years\",\n",
    "        \"200\": \"200 years\",\n",
    "        200.0: \"200 years\",\n",
    "        \"500\": \"500 years\",\n",
    "        500.0: \"500 years\",\n",
    "        \"1000\": \"1000 years\",\n",
    "        1000.0: \"1000 years\", \n",
    "    },\n",
    "    \"scenarios\": {\n",
    "        \"None\": \"No Scenario\",\n",
    "        \"SSP126\": \"SSP1-2.6\",\n",
    "        \"SSP245\": \"SSP2-4.5\",\n",
    "        \"SSP585\": \"SSP5-8.5\",\n",
    "        \"ssp126\": \"SSP1-2.6\",\n",
    "        \"ssp245\": \"SSP2-4.5\",\n",
    "        \"ssp585\": \"SSP5-8.5\",\n",
    "        \"High_End\": \"High End\",\n",
    "        \"high_end\": \"High End\",\n",
    "        \"Historical\": \"Historical\",\n",
    "        \"RCP45\": \"RCP 4.5\",\n",
    "        \"RCP85\": \"RCP 8.5\"\n",
    "    },\n",
    "    \"time\": {\n",
    "        \"2010\": \"2010\",\n",
    "        \"2030\": \"2030\",\n",
    "        \"2050\": \"2050\",\n",
    "        \"2100\": \"2100\",\n",
    "        \"2150\": \"2150\",\n",
    "        # Added years with rounding to the nearest decade\n",
    "        \"2031\": \"2030\",\n",
    "        \"2041\": \"2040\",\n",
    "        \"2051\": \"2050\",\n",
    "        \"2061\": \"2060\",\n",
    "        \"2071\": \"2070\",\n",
    "        \"2081\": \"2080\",\n",
    "        \"2091\": \"2090\",\n",
    "        \"2101\": \"2100\",\n",
    "        \"2111\": \"2110\",\n",
    "        \"2121\": \"2120\",\n",
    "        \"2131\": \"2130\",\n",
    "        \"2141\": \"2140\",\n",
    "        \"2151\": \"2150\"\n",
    "    },\n",
    "    \"ensemble\": {\n",
    "        \"msl_l\": \"16.7 Percentile\",\n",
    "        \"msl_m\": \"50.0 Percentile\",\n",
    "        \"msl_h\": \"83.3 Percentile\"\n",
    "    },\n",
    "    \"adaptation strategy\": {\n",
    "        \"no_adaptation\": \"No Adaptation\",\n",
    "        \"retreat\": \"Retreat\",\n",
    "        \"protection\": \"Protect\",\n",
    "        \"acc\": \"Accommodate\",\n",
    "        \"protect_retreat\": \"Protect & Retreat\"\n",
    "    },\n",
    "    \"variables\": {\n",
    "        \"hs\": \"Wave height (Hs)\",\n",
    "        \"ssl\": \"Storm surge level (SSL)\",\n",
    "        \"slr\": \"Sea level rise (SLR)\",\n",
    "        \"tidal_range\": \"Tidal range\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# Also add descriptions\n",
    "fe_descriptions = {\n",
    "    \"defense level\": \"Policy-based coastal protection standards at the province level (NUTS2). High (low) defended: maximum (minimum) level of policy-based protection, if information is available. No defense: without protection (beyond what may be included in the DEM)\",\n",
    "    \"return period\": \"Frequency at which an extreme event of total water level (related to storms) is expected to occur on average.\",\n",
    "    \"rp\": \"Frequency at which an extreme event of total water level (related to storms) is expected to occur on average.\",\n",
    "    \"scenarios\": \"Climate scenarios based on IPCC's Shared Socioeconomic Pathways (SSPs). High-end (if applicable) refers to P83 of SSP5-8.5, taking into account low-confidence processes. Other scenarios use the P50\",\n",
    "    \"time\": \"Time slice applied to the data. Either present-day (2010) or future state representing medium (2030 till 2050) and long term (2050 till 2100) outlook.\",\n",
    "    \"ensemble\": \"Uncertainty range of projections. 16.7, 50 and 83.3 indicate the lower bound, median and upper bound respectively\",\n",
    "    \"adaptation strategy\": \"The adaptation strategy related to raising coastal defenses (protection), managed withdrawal from vulnerable areas (retreat), a combination of these strategies (protect & retreat), implementing flood-proofing measures (accommodation) or areas where adaptation measure are deemed inefficient (no adaptation)\",\n",
    "    \"variables\": \"Different variables included in the dataset\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up function for checking a collection based on a list of titles\n",
    "\n",
    "def update_collection_FE_text(collection, fe_text_file, fe_labels, fe_descriptions):\n",
    "\n",
    "    # Load FE_text excel file\n",
    "    fe_text = pd.read_excel(fe_text_file, sheet_name=\"Sheet1\")\n",
    "\n",
    "    # Check if collection ID is in the FE_text\n",
    "    collection_id = collection.id\n",
    "\n",
    "    if not fe_text[fe_text[\"Collection\"] == collection_id].empty:\n",
    "        print('Collection found in FE-text, metadata will be updated for: ' + collection_id)\n",
    "\n",
    "        # Retrieve info from FE_text\n",
    "        fe_title = fe_text.loc[fe_text[\"Collection\"] == collection_id, \"Title\"].values[0]\n",
    "        fe_description = fe_text.loc[fe_text[\"Collection\"] == collection_id, \"Markdown\"].values[0]\n",
    "        fe_keywords = fe_text.loc[fe_text[\"Collection\"] == collection_id, \"Keywords\"].values[0].split(\", \")\n",
    "        fe_styling = fe_text.loc[fe_text[\"Collection\"] == collection_id, \"Styling\"]\n",
    "        \n",
    "        # Check if excel cell contains data\n",
    "        if isinstance(fe_title, str):\n",
    "            # Change collection title\n",
    "            collection.title = fe_title\n",
    "\n",
    "        # Check if excel cell contains data\n",
    "        if isinstance(fe_description, str):\n",
    "            # Change collection description\n",
    "            collection.description = fe_description\n",
    "        \n",
    "        # Check if excel cell contains data\n",
    "        if isinstance(fe_keywords, str):\n",
    "            # Change collection keywords\n",
    "            collection.keywords.extend(fe_keywords)\n",
    "        \n",
    "        # Retrieve styling from FE_text\n",
    "        # Check if excel cell contains data\n",
    "        if fe_styling.empty or fe_styling.isna().all() or fe_styling.str.strip().eq('').all():\n",
    "            # No styling found\n",
    "            print(f\"No styling found for collection {collection_id}, skipping...\")\n",
    "        else:      \n",
    "            # Convert the JSON string into a Python dictionary\n",
    "            styling = json.loads(fe_text.loc[fe_text[\"Collection\"] == collection_id, \"Styling\"].values[0])\n",
    "\n",
    "            # Iterate over the keys and values of the dictionary\n",
    "            for key, value in styling.items():\n",
    "                if key.startswith('deltares:'):\n",
    "                    # Change the collection properties\n",
    "                    collection.extra_fields[key] = value\n",
    "\n",
    "        # Add front-end labels to the collection\n",
    "        collection = add_FE_labels_to_collection(collection, fe_labels, fe_descriptions)\n",
    "\n",
    "        # Save collection\n",
    "        collection.save()\n",
    "\n",
    "    else:\n",
    "        print('Collection not found in FE-text, no metadata update needed...')\n",
    "\n",
    "def add_FE_labels_to_collection(collection, fe_labels, fe_descriptions):\n",
    "    # Initialize an empty dict to store the front-end labels and descriptions\n",
    "    summaries_labels = {}\n",
    "    summaries_descriptions = {}\n",
    "\n",
    "    # Get summaries as a dictionary\n",
    "    summaries_dict = collection.summaries.to_dict()\n",
    "\n",
    "    # Iterate over the summaries dictionary\n",
    "    for key, values in summaries_dict.items():\n",
    "        if key in fe_labels:  # Check if the key has front-end labels\n",
    "            label_map = fe_labels[key]  # Get the label mapping for the key\n",
    "            # Map the original summary values to the front-end labels\n",
    "            summaries_labels[key] = {value: label_map.get(value, value) for value in values}\n",
    "            \n",
    "        # Add the front-end description for the key if it exists in fe_descriptions\n",
    "        if key in fe_descriptions:\n",
    "            summaries_descriptions[key] = fe_descriptions[key]\n",
    "    # Add the summaries_labels to the collection properties\n",
    "    collection.extra_fields['summaries_labels'] = summaries_labels\n",
    "\n",
    "    # Add the front-end info description to the collection\n",
    "    collection.extra_fields['summaries_descriptions'] = summaries_descriptions\n",
    "\n",
    "    return collection\n",
    "\n",
    "def update_catalog_FE_text(catalog, fe_text_file, fe_labels, fe_descriptions):\n",
    "    \n",
    "    # Load FE_text excel file\n",
    "    fe_text = pd.read_excel(fe_text_file, sheet_name=\"Sheet1\")\n",
    "\n",
    "    # Get all collections from FE_text\n",
    "    fe_collections = fe_text[\"Collection\"].unique()\n",
    "\n",
    "    # Loop through collections and update metadata\n",
    "    for fe_collection_id in fe_collections:\n",
    "\n",
    "        # Check if collection_id exists in the catalog\n",
    "        if not catalog.get_child(fe_collection_id):\n",
    "            print(f'Collection {fe_collection_id} not found in catalog, skipping...')\n",
    "            continue\n",
    "\n",
    "        print(f'Updating collection: {fe_collection_id}')\n",
    "        collection = catalog.get_child(fe_collection_id)\n",
    "        update_collection_FE_text(collection, fe_text_file, fe_labels, fe_descriptions)\n",
    "\n",
    "        catalog.save()\n",
    "\n",
    "def reset_catalog(folder=\"current\", branch=\"main\"):\n",
    "    # Get the current working directory (should be in the 'notebooks' folder)\n",
    "    current_dir = Path.cwd()\n",
    "\n",
    "    # Go up two levels to reach the Git repo root\n",
    "    repo_path = current_dir.parents[0]  # Adjust if necessary\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"git\", \"checkout\", branch, \"--\", folder],\n",
    "            check=True,\n",
    "            cwd=repo_path  # Ensure git is executed from the repo root\n",
    "        )\n",
    "        print(f\"✅ STAC Catalog and collections in folder: '{folder}' reset to match '{branch}' branch.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Git command failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ STAC Catalog and collections in folder: 'current' reset to match 'main' branch.\n"
     ]
    }
   ],
   "source": [
    "reset_catalog(folder=\"current\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating collection: slp\n",
      "Collection found in FE-text, metadata will be updated for: slp\n",
      "Updating collection: ssl\n",
      "Collection found in FE-text, metadata will be updated for: ssl\n",
      "No styling found for collection ssl, skipping...\n",
      "Updating collection: eesl\n",
      "Collection found in FE-text, metadata will be updated for: eesl\n",
      "No styling found for collection eesl, skipping...\n",
      "Updating collection: cfhp_all_maps\n",
      "Collection found in FE-text, metadata will be updated for: cfhp_all_maps\n",
      "Updating collection: coaster\n",
      "Collection found in FE-text, metadata will be updated for: coaster\n",
      "Updating collection: cba\n",
      "Collection found in FE-text, metadata will be updated for: cba\n",
      "Updating collection: be_maps\n",
      "Collection found in FE-text, metadata will be updated for: be_maps\n",
      "Updating collection: pp_maps\n",
      "Collection found in FE-text, metadata will be updated for: pp_maps\n",
      "Updating collection: bc_maps\n",
      "Collection found in FE-text, metadata will be updated for: bc_maps\n",
      "Updating collection: LAU_CM\n",
      "Collection found in FE-text, metadata will be updated for: LAU_CM\n",
      "No styling found for collection LAU_CM, skipping...\n",
      "Updating collection: NUTS0_CM\n",
      "Collection found in FE-text, metadata will be updated for: NUTS0_CM\n",
      "No styling found for collection NUTS0_CM, skipping...\n",
      "Updating collection: NUTS2_CM\n",
      "Collection found in FE-text, metadata will be updated for: NUTS2_CM\n",
      "No styling found for collection NUTS2_CM, skipping...\n",
      "Updating collection: cfhp_all\n",
      "Collection found in FE-text, metadata will be updated for: cfhp_all\n",
      "Updating collection: twl_SLR\n",
      "Collection found in FE-text, metadata will be updated for: twl_SLR\n",
      "No styling found for collection twl_SLR, skipping...\n",
      "Updating collection: twl_SLR_RP\n",
      "Collection found in FE-text, metadata will be updated for: twl_SLR_RP\n",
      "No styling found for collection twl_SLR_RP, skipping...\n",
      "Updating collection: drivers_twl\n",
      "Collection found in FE-text, metadata will be updated for: drivers_twl\n",
      "No styling found for collection drivers_twl, skipping...\n",
      "Updating collection: pp\n",
      "Collection found in FE-text, metadata will be updated for: pp\n",
      "Updating collection: ceed_maps\n",
      "Collection found in FE-text, metadata will be updated for: ceed_maps\n",
      "No styling found for collection ceed_maps, skipping...\n"
     ]
    }
   ],
   "source": [
    "update_catalog_FE_text(catalog,fe_text_file, fe_labels, fe_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coclico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
